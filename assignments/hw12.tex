\documentclass[letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{enumerate}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhead[L]{STAT 542 HW12}
\fancyhead[R]{Xin Yin}

\newcommand{\intii}{\int_{-\infty}^\infty}
\newcommand{\intzi}{\int_0^\infty}
\newcommand{\convp}{\stackrel{p}{\to}}
\newcommand{\convd}{\stackrel{d}{\to}}
\newcommand{\IID}{\stackrel{iid}{\sim}}
\newcommand{\pbt}{\frac{p}{2}}
\newcommand{\qbt}{\frac{q}{2}}
\newcommand{\pqbt}{\frac{p+q}{2}}
\newcommand{\sumn}[1]{\sum_{#1=1}^n}
\newcommand{\smpmean}[1]{\cfrac{\sum_{i=1}^n #1}{n}}
\newcommand{\bZ}{\mathbf{Z}}
\renewcommand{\arraystretch}{1.5}

\begin{document}
\section*{Q1}
\begin{enumerate}
\item Since $X_1, \dots, X_n \IID \text{Poisson}(\lambda)$, by law of large numbers, $\bar X_n \convp EX_i = \lambda$.
Define $g(x) = xe^{-x}$, and obviously $g(x)$ is a continuous function. So, by mapping theorem, we have,
\[
g(\bar X_n) = \bar X_n e^{-\bar X_n} \convp g(\lambda) = \lambda e^{-\lambda},
\]
\emph{i.e.} $\hat \eta_n \convp \eta$.
\item Since $X_1, \dots, X_n \IID \text{Poisson}(\lambda)$, using CLT, we know that, $\sqrt{n}(\bar X_n - \lambda) \convd N(0, \lambda)$, as $Var(X_i) = \lambda$. 
Given the function $g$ we defined in previous question, using delta method, we have that,
\[
\sqrt{n}\left[ g(\bar X_n) - g(\lambda) \right] \convd N(0, \lambda [g'(\lambda)]^2)
\]
where 
\[
g'(\lambda) = \left. \frac{d}{dx} xe^{-x} \right|_{x =\lambda} = e^{-\lambda} - \lambda e^{-\lambda} = (1-\lambda) e^{-\lambda}.
\]

Therefore, 
\[
\sqrt{n}[\hat \eta_n - \eta] = \sqrt{n}\left[ g(\bar X_n) - g(\lambda) \right] \convd N(0, \lambda (1-\lambda)^2 e^{-2\lambda}),
\]
\emph{i.e.}, $\hat \eta_n$ is $AN(\lambda e^{-\lambda}, \lambda (1-\lambda)^2 e^{-2\lambda})$
\end{enumerate}
\section*{Q2}
\begin{enumerate}
\item The pearson correlation coefficient is defined as,
\[
\rho_{X, Y} = \frac{Cov(X, Y)}{\sqrt{Var(X) Var(Y)}} = \frac{EXY - EXEY}{\sqrt{(EX^2 - (EX)^2)(EY^2 - (EY)^2)}}
\]
By plug-in, we can write down the sample pearson correlation coefficient as,
\[
\hat \rho = \frac{\smpmean{X_i Y_i} - \smpmean{X_i} \smpmean{Y_i}}{\sqrt{\left[\smpmean{X_i^2}-\left(\smpmean{X_i}\right)^2\right]\left[\smpmean{Y_i^2} - \left(\smpmean{Y_i}\right)^2\right]}}
\]

Given that $(X_1, Y_1), \dots, (X_n, Y_n) \IID F$, if we define iid random vector $\bZ_i = (X_i, Y_i, X_i^2, Y_i^2, X_i Y_i)$, we can show that, by using law of large number, 
\[
\bar \bZ_n^T = (\smpmean{X_i}, \smpmean{Y_i}, \smpmean{X_i^2}, \smpmean{Y_i^2}, \smpmean{X_i Y_i})^T \convp (EX, EY, EX^2, EY^2, EXY)^T
\]

Now define a function $g(x_1, x_2, x_3, x_4, x_5) = \cfrac{x_5 - x_1 x_2}{\sqrt{(x_3 - x_1^2)(x_4 - x_2^2)}}$, we can easily see that,
\begin{eqnarray*}
\rho = g(EX, EY, EX^2, EY^2, EXY) \\
\hat \rho = g(\bar \bZ_n) = g(\smpmean{X_i}, \smpmean{Y_i}, \smpmean{X_i^2}, \smpmean{Y_i^2}, \smpmean{X_i Y_i})
\end{eqnarray*}
Since $g$ is a continuous function, using mapping theorem, we have that,
\[
\hat \rho \convp \rho
\]
\item
We first try to work out the $D$ matrix, which is $\left. \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}} \right|_{\mathbf{x} = \mathbf{\mu}}$.
\[
D = \left. \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}} \right|_{\mathbf{x} = \mathbf{\mu}} = \begin{pmatrix}
\frac{\frac{2 \mu_X \sigma_Y}{\sigma_X} (\mu_{XY} - \mu_X \mu_Y)}{\sigma_X^2\sigma^2_Y} \\
\frac{\frac{2 \mu_Y \sigma_X}{\sigma_Y} (\mu_{XY} - \mu_X \mu_Y)}{\sigma_X^2\sigma^2_Y} \\
-\frac{\mu_{XY} - \mu_X \mu_Y}{2\sigma_X^3 \sigma_Y}\\
-\frac{\mu_{XY} - \mu_X \mu_Y}{2\sigma_X \sigma_Y^3}\\
\frac{1}{\sigma_X \sigma_Y}
\end{pmatrix}^T
\]
The variance-covariance matrix $\Sigma$ for random vector $\bZ_i$, is,
\[
\Sigma = \begin{pmatrix}
Var(X_i) & Cov(X_i, Y_i) & Cov(X_i, X_i^2) & Cov(X_i, Y_i^2) & Cov(X_i, X_i Y_i) \\
Cov(X_i, Y_i) & Var(Y_i) & Cov(Y_i, X_i^2) & Cov(Y_i, Y_i^2) & Cov(Y_i, X_i Y_i)\\
Cov(X_i, X_i^2) & Cov(Y_i, X_i^2) & Var(X_i^2) & Cov(X_i^2, Y_i^2) & Cov(X_i^2, X_i Y_i) \\
Cov(X_i, Y_i^2) & Cov(Y_i, Y_i^2) & Cov(X_i^2, Y_i^2) & Var(Y_i^4) & Cov(X_i^2, X_i Y_i) \\
Cov(X_i, X_i Y_i) & Cov(Y_i, X_i Y_i) & Cov(X_i^2, X_i Y_i) & Cov(Y_i^2, X_i Y_i) & Var(X_i Y_i) \\
\end{pmatrix}
\]
This matrix exists since the fourth moment of $F$ exists.

So, the asymptotic variance of $\hat \rho$ is $D\Sigma D^T$, where $D$ and $\Sigma$ are matrices stated above.
\end{enumerate}

\section*{5.15}
\begin{enumerate}[(a)]
\item
\begin{align*}
rhs: \qquad \frac{X_{n+1} + n \bar X_n}{n+1} & = \frac{X_{n+1} + n \frac{\sum_{i=1}^n X_i}{n}}{n+1} \\
& = \frac{\sum_{i=1}^{n+1} X_i}{n+1} = \bar X_{n+1} = lhs
\end{align*}
\item 
\begin{align*}
lhs: \qquad n S_{n+1}^2 & = \sum_{i=1}^{n+1} (X_i - \bar X_{n+1})^2 \\
& = \sum_{i=1}^n (X_i - \bar X_n + \bar X_n - \bar X_{n+1})^2 + (X_{n+1} - \bar X_{n+1})^2
\\
& \text{The first term can be expanded as},\\
\sum_{i=1}^n (X_i - \bar X_n + \bar X_n - \bar X_{n+1})^2 & = \sum_{i=1}^n (X_i - \bar X_n)^2 + 2 \sum_{i=1}^n (X_i - \bar X_n)(\bar X_n - \bar X_{n+1}) \sum_{i=1}^n (\bar X_n - \bar X_{n+1})^2 \\
& = (n-1)S_n^2 + 0 + \sum_{i=1}^n \left(\frac{\bar X_n - X_{n+1}}{n+1}\right)^2 \\
& = (n-1)S_n^2 + \frac{n(X_{n+1} - \bar X_n)^2}{(n+1)^2} \\
\\
& \text{The second term is},\\
(X_{n+1} - \bar X_{n+1})^2 & = \left(\frac{(n+1) X_{n+1}}{n+1} - \frac{X_{n+1} - n \bar X_n}{n+1}\right)^2 = \frac{n^2(X_{n+1} - \bar X_n)^2}{(n+1)^2} \\
\\
& \text{So,}\\
nS_{n+1}^2 & = (n-1)S_n^2 + \frac{n(X_{n+1} - \bar X_n)^2}{(n+1)^2} + \frac{n^2(X_{n+1} - \bar X_n)^2}{(n+1)^2} \\
& = (n-1)S_n^2 + \frac{n}{n+1}(X_{n+1} - \bar X_n)^2 \\
& = rhs.
\end{align*}
\end{enumerate}
\section*{5.16}
\begin{enumerate}[(a)]
\item Since $X_i \sim N(i, i^2)$, $\frac{X_i - i}{i} \sim N(0, 1)$, which implies that, $\left(\frac{X_i - i}{i}\right)^2 \sim \chi_1^2$.
So,
\[
\sum_{i=1}^3 \left(\frac{X_i - i}{i}\right)^2 \sim \chi_3^2
\]
\item
Given $U \sim N(0, 1), V \sim \chi^2_\nu$, 
\[
T = \frac{U}{\sqrt{V/\nu}} \sim T_\nu
\]

So, 
\[
\cfrac{\frac{X_i - i}{i}}{\sqrt{\cfrac{\sum_{i=1}^2 \left(\frac{X_i-i}{i} \right)^2}{2}}} \sim t_2
\]
\item Since given $T \sim t_\nu$, $T^2 \sim F_{1, \nu}$, and we derived $t_2$ above, then,
\[
\left(\frac{\frac{X_i - i}{i}}{\sqrt{\cfrac{\sum_{i=1}^2 \left(\frac{X_i-i}{i} \right)^2}{2}}}\right)^2 \sim F_{1,2}
\]
\end{enumerate}
\section*{5.17}
\begin{enumerate}[(a)]
\item
Let $U \sim \chi^2_p, V \sim \chi^2_q$ be independent random variables. So,
\[
f_{U,V}(u, v) = \frac{1}{\Gamma(\pbt)2^{\pbt}} u^{\pbt-1} e^{-u/2} \frac{1}{\Gamma(\qbt)2^{\qbt}} v^{\qbt-1} e^{-v/2} = \frac{1}{\Gamma(\pbt)\Gamma(\qbt)2^{\pqbt}} u^{\pbt-1} v^{\qbt-1} e^{-\pqbt} 
\]

Now let $X = \frac{U/p}{V/q}, Y = V$, and we can solve that,
\[
U = \frac{p}{q} XY, \quad V = Y
\]
and the Jacobian is,
\[
J = \begin{vmatrix}
\frac{\partial \frac{p}{q} xy}{\partial x} & \frac{\partial \frac{p}{q} xy}{\partial y} \\
\frac{\partial y}{\partial x} & \frac{\partial y}{\partial y} \\
\end{vmatrix} = \frac{p}{q} y
\]

So, 
\begin{align*}
f_{X,Y}(x, y) & = f_{U, V}(\frac{p}{q} xy, y) |J| = \frac{1}{\Gamma(\pbt)\Gamma(\qbt)2^{\pqbt}} (\frac{p}{q})^{\pbt} x^{\pbt - 1} y^{\pqbt-1} e^{-\frac{y(\frac{p}{q} x +1)}{2}} \\
& = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} \frac{x^{\pbt-1}}{[1+(p/q)x]^{\pqbt}} \frac{[(1+\frac{p}{q}x)y]^{\pqbt-1} e^{-\frac{y(\frac{p}{q} x +1)}{2}}}{\Gamma(\pqbt)2^{\pqbt}} (\frac{p}{q} x+ 1) \\
& \text{Now let}~u = (\frac{p}{q} x + 1)y \implies y = \frac{u}{\frac{p}{q} x + 1}, dy = \frac{du}{\frac{p}{q} x + 1}.\\
f_X(x) & = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} \frac{x^{\pbt-1}}{[1+(p/q)x]^{\pqbt}} \intzi \frac{[(1+\frac{p}{q}x)y]^{\pqbt-1} e^{-\frac{y(\frac{p}{q} x +1)}{2}}}{\Gamma(\pqbt)2^{\pqbt}} (\frac{p}{q} x+ 1) dy \\
& = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} \frac{x^{\pbt-1}}{[1+(p/q)x]^{\pqbt}} \intzi \frac{u^{\pqbt-1} e^{-u/2}}{\Gamma(\pqbt)2^{\pqbt}} du \\
& \text{Notice that the integral equals 1 because the integrand is a gamma pdf},\\
& = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} \frac{x^{\pbt-1}}{[1+(p/q)x]^{\pqbt}}
\end{align*}
And $f_X(x)$ is the pdf for $F_{p, q}$ distribution.
\item
Since $X = \frac{U/p}{V/q} \sim F_{p, q}$, where $U \sim \chi^2_p, V \sim \chi^2_q$ are independent..
\begin{align*}
E(X) & = E(\frac{U/p}{V/q}) = E(U/p) E(\frac{1}{V/q}) = q E(1/V) \\
& = q \intzi \frac{1}{v} \frac{1}{\Gamma(\qbt)2^{\qbt}} v^{\qbt-1} e^{-v/2} dv\\
& = q \frac{\Gamma(\frac{q-2}{2})}{\Gamma(\frac{q}{2}) 2} \intzi \frac{1}{\Gamma(\frac{q-2}{2}) 2^{\frac{q-2}{2}}} v^{\frac{q-2}{2} -1} e^{-v/2} dv \\
& = \frac{q}{q-2}, \qquad q > 2
\end{align*}
\item $X = \frac{U/p}{V/q} \sim F_{p, q}$, then $X^{-1} = \frac{V/q}{U/p}$, where $V \sim \chi^2_q, U \sim \chi^2_p$. Then,
\[
X^{-1} \sim F_{q, p}
\]
\item
Let $y = \frac{(p/q)x}{1+(p/q)x}, 0 < y < 1$. $g^{-1}(y) = \frac{y}{(p/q)(1-y)}$ is continous and monotone on (0, 1). Therefore,
\begin{align*}
f_Y(y) & = f_X(g^{-1}(y)) \left|\frac{d}{dy} g^{-1}(y)\right| \\
& = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} (\frac{p}{q})^{\pbt} \frac{\left(\frac{y}{1-y}\right)^{\pbt-1} \left(\frac{p}{q}\right)^{1-\pbt}}{\left(\frac{1}{1-y}\right)^{\pqbt}} \frac{1}{\frac{p}{q} (1-y)^2} \\
& = \frac{\Gamma(\pqbt)}{\Gamma(\pbt)\Gamma(\qbt)} y^{\pbt-1} (1-y)^{\qbt-1}
\end{align*}
which is the pdf for a Beta$(\pbt, \qbt)$ distribution.

\end{enumerate}
\section*{5.18}
\begin{enumerate}[(a)]
\item 
\begin{align*}
ET & = \intii t f_T(t) dt = \intii t \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)} \frac{1}{\sqrt{p\pi}} \frac{1}{(1+t^2/p)^{(p+1)/2}} \\
& = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)} \frac{1}{\sqrt{p\pi}} \frac{p}{2} \intii (1+t^2/p)^{-(p+1)/2} d(1+t^2/p) \\
& = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)} \frac{1}{\sqrt{p\pi}} \frac{p}{2} \frac{2}{1-p}  \left. (1+t^2/p)^{(1-p)/2}\right|_{-\infty}^\infty \\
\end{align*}
As we can see, if $0 < p \le 1, \lim_{t \to \infty} (1+t^2/p)^{(1-p)/2} \to \infty$ that is unbounded. Therefore $ET$ doesn't exist for $p \le 1$.

For $p > 1$, since $ET$ is an odd function, we have $ET = 0$. Hence,
\[
ET = 0, \quad p > 1.
\]

Let $T = \frac{U}{\sqrt{V/p}}$, where $U \sim N(0,1), V \sim \chi^2_p$ and are independent. So, $T \sim t_p$. Then,
\[
ET = E(\frac{U}{\sqrt{V/p}}) = E(U) E(\frac{1}{\sqrt{V/p}})
\]
If $ET$ exists, then $ET = 0$. So, $Var(T) = ET^2$, where $T^2 \sim F_{1, p}$. 
From 5.17(b), $ET^2 = \frac{p}{p-2}, \quad p > 2$. Therefore, 
\[
Var(T) = \frac{p}{p-2}, \quad p > 2
\]
\item
Let $Y = g(x) = x^2, 0 < y < \infty$. We partition the support for $X$, $(-\infty, \infty)$ into $A_0 = \{0\}, A_1 = (-\infty, 0), A_2 = (0, \infty)$. 
So, $g^{-1}_1(y) = -\sqrt{y}, g^{-1}_2(y) = \sqrt{y}$. And $g_i$ is monotone and continuous on $A_i, i = 1, 2$.

So,
\begin{align*}
f_Y(y) & = f_X(-\sqrt{y}) \frac{1}{2\sqrt{y}} + f_X(\sqrt{y}) \frac{1}{2\sqrt{y}} = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)} \frac{1}{\sqrt{p\pi}} \frac{1}{(1+y/p)^{(p+1)/2}} \frac{1}{\sqrt{y}} \\
& \text{As}~\Gamma(\frac{1}{2}) = \sqrt{\pi}, \\
& = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)\Gamma(\frac{1}{2})} \left(\frac{1}{p}\right)^\frac{1}{2} \frac{y^{1/2-1}}{\left(1+\frac{1}{p} y \right)^{(1+p)/2}}
\end{align*}
And we can identify that this is the pdf for $F_{1, p}$. Therefore, $X^2$ has a $F$ distribution with 1 and $p$ degrees of freedom.
\item
The pdf $f(x|p)$ for a $t$ distribution with degrees of freedom $p$ is,
\[
f(x|p) = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(\pbt)} \frac{1}{\sqrt{p\pi}} \frac{1}{(1+t^2/p)^{(p+1)/2}}
\]

Since for the part $\frac{1}{(1+t^2/p)^{(p+1)/2}}$,
\[
\lim_{p \to \infty} \frac{1}{(1+t^2/p)^{(p+1)/2}} = \lim_{p \to \infty} \frac{1}{\left(\frac{1+\frac{p+1}{p} \frac{t^2}{2}}{\frac{p+1}{2}}\right)^{(p+1)/2}} = \frac{1}{e^{t^2/2}} = e^{-t^2/2}
\]
\item
Directly using the result of (c), since $X \convd N(0, 1)$ as $p \to \infty$, then $X^2 \convd \chi^2_1$.
\end{enumerate}
\end{document}
